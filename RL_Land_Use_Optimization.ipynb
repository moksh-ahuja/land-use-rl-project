{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMawNbPZ0sTI49DDmZbjMth",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moksh-ahuja/land-use-rl-project/blob/main/RL_Land_Use_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy matplotlib pandas gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "76KO-jbib51m",
        "outputId": "a4e3b0a2-7480-4b41-be1c-b0736c683ef9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra] optuna --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sd80NtXB5jYT",
        "outputId": "28f7bcfd-8919-4045-c1b2-36ccbeb4dde9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up RL Environment"
      ],
      "metadata": {
        "id": "16LvNkO-nlHY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "BMBBNQB2bQmr"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gymnasium import spaces\n",
        "\n",
        "class LandUseOptimizationEnv(gym.Env):\n",
        "    def __init__(self, df, region_list, forecast_years=25):\n",
        "        super().__init__()\n",
        "        self.data = df.copy()\n",
        "        self.regions = region_list\n",
        "        self.forecast_years = forecast_years\n",
        "\n",
        "        self.year_index = 0\n",
        "        self.years = sorted(self.data['year'].unique())\n",
        "        self.current_year = self.years[self.year_index]\n",
        "        self.end_year = self.years[min(self.forecast_years, len(self.years) - 1)]\n",
        "        self.num_regions = len(self.regions)\n",
        "        self.region = self.regions[0]\n",
        "        self.total_land = 100_000\n",
        "\n",
        "        self.target_forest_share = 0.33\n",
        "        self.env_degradation = 0.0\n",
        "\n",
        "        self.forest_history = []\n",
        "        self.co2_history = []\n",
        "\n",
        "        self.action_space = spaces.Box(low=np.array([0.0, 0.0, 0.0]), high=np.array([1.0, 1.0, 1.0]), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(low=-5.0, high=5.0, shape=(11,), dtype=np.float32)\n",
        "        self.previous_allocation = np.array([0.48, 0.33, 0.19], dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        action = np.clip(action, 0, 1)\n",
        "        if np.sum(action) == 0:\n",
        "            action = np.array([0.48, 0.33, 0.19], dtype=np.float32)\n",
        "        else:\n",
        "            action = action / np.sum(action)\n",
        "\n",
        "        agri_share, forest_share, solar_share = action\n",
        "\n",
        "        row = self.data[(self.data['year'] == self.current_year) & (self.data['region'] == self.region)].iloc[0]\n",
        "        food_production = agri_share * row['agri_yield'] * row['total_land']\n",
        "        food_required = max(row['population'] * 0.35, 1e-8)\n",
        "        food_gap = food_production - food_required\n",
        "        food_ratio = food_production / food_required\n",
        "\n",
        "        solar_energy = solar_share * row['solar_efficiency'] * row['total_land']\n",
        "        forest_co2 = forest_share * row['co2_per_forest_km2'] * row['total_land'] * (1 - self.env_degradation)\n",
        "        solar_co2 = solar_energy * row['carbon_price']\n",
        "        co2_reduction = forest_co2 + solar_co2\n",
        "\n",
        "        agri_revenue = food_production * row['energy_price']\n",
        "        solar_cost = solar_share * row['solar_install_cost']\n",
        "        net_revenue = agri_revenue - solar_cost\n",
        "\n",
        "        export_revenue = 0.0\n",
        "        export_carbon_cost = 0.0\n",
        "        if food_gap > 0:\n",
        "            export_revenue = food_gap * row['energy_price'] * 0.5\n",
        "            export_carbon_cost = food_gap * 0.1\n",
        "\n",
        "        co2_reduction -= export_carbon_cost\n",
        "\n",
        "        if forest_share < self.target_forest_share:\n",
        "            self.env_degradation = min(1.0, self.env_degradation + 0.15 * (self.target_forest_share - forest_share))\n",
        "        else:\n",
        "            self.env_degradation = max(0.0, self.env_degradation - 0.05)\n",
        "\n",
        "        self.forest_history.append(forest_share)\n",
        "        if len(self.forest_history) > 3:\n",
        "            self.forest_history.pop(0)\n",
        "\n",
        "        scaled_co2_reduction = co2_reduction / 1e8\n",
        "        if not np.isfinite(scaled_co2_reduction):\n",
        "            scaled_co2_reduction = 0.0\n",
        "        self.co2_history.append(scaled_co2_reduction)\n",
        "        if len(self.co2_history) > 3:\n",
        "            self.co2_history.pop(0)\n",
        "\n",
        "        food_reward = min(100, food_ratio * 50)  # No penalty for overproduction\n",
        "        forest_reward = min(100, (forest_share / self.target_forest_share) * 150)  # Higher scaling to prioritize forest\n",
        "        co2_reward = min(100, (co2_reduction / 1e8) * 150) * (1 - self.env_degradation)  # Higher scaling for CO2\n",
        "        revenue_reward = min(100, ((net_revenue + export_revenue) / 1e6) * 100) * (1 - self.env_degradation)\n",
        "\n",
        "        reward = (food_reward + forest_reward + co2_reward + revenue_reward) / 4\n",
        "\n",
        "        if not np.isfinite(reward):\n",
        "            reward = -100.0\n",
        "\n",
        "        self.previous_allocation = action\n",
        "        self.year_index += 1\n",
        "        done = self.year_index >= len(self.years)\n",
        "        if not done:\n",
        "            self.current_year = self.years[self.year_index]\n",
        "\n",
        "        obs = self._get_obs()\n",
        "        obs = np.nan_to_num(obs, nan=0.0, posinf=5.0, neginf=-5.0)\n",
        "\n",
        "        info = {\n",
        "            \"food_production\": food_production,\n",
        "            \"food_required\": food_required,\n",
        "            \"food_gap\": food_gap,\n",
        "            \"forest_share\": forest_share,\n",
        "            \"solar_energy\": solar_energy,\n",
        "            \"co2_reduction\": co2_reduction,\n",
        "            \"agri_revenue\": agri_revenue,\n",
        "            \"solar_cost\": solar_cost,\n",
        "            \"export_revenue\": export_revenue,\n",
        "            \"export_carbon_cost\": export_carbon_cost,\n",
        "            \"year\": self.current_year,\n",
        "            \"region\": self.region,\n",
        "            \"agri_share\": agri_share,\n",
        "            \"env_degradation\": self.env_degradation\n",
        "        }\n",
        "\n",
        "        terminated = self.current_year >= self.end_year\n",
        "        truncated = False\n",
        "        return obs, reward, bool(terminated), bool(truncated), info\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.year_index = 0\n",
        "        self.current_year = self.years[self.year_index]\n",
        "        self.region = self.regions[0]\n",
        "        self.previous_allocation = np.array([0.48, 0.33, 0.19], dtype=np.float32)\n",
        "        self.forest_history = []\n",
        "        self.co2_history = []\n",
        "        self.env_degradation = 0.0\n",
        "        return self._get_obs(), {}\n",
        "\n",
        "    def _get_obs(self):\n",
        "        row = self.data[(self.data['year'] == self.current_year) & (self.data['region'] == self.region)].iloc[0]\n",
        "        obs = [\n",
        "            row['population_norm'],\n",
        "            row['agri_yield_norm'],\n",
        "            row['rainfall_norm'],\n",
        "            row['energy_price_norm'],\n",
        "            row['solar_install_cost_norm'],\n",
        "            row['carbon_price_norm'],\n",
        "            *self.previous_allocation,\n",
        "            np.mean(self.co2_history[-3:]) if self.co2_history else 0.0,\n",
        "            self.env_degradation\n",
        "        ]\n",
        "        return np.array(obs, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Synthetic Data"
      ],
      "metadata": {
        "id": "ZQw2aLnBnqU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import random\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "def generate_synthetic_data(regions=[\"Region_1\", \"Region_2\", \"Region_3\", \"Region_4\", \"Region_5\"],\n",
        "                            start_year=2025,\n",
        "                            end_year=2050):\n",
        "    data = []\n",
        "\n",
        "    years = list(range(start_year, end_year + 1))\n",
        "\n",
        "    for region in regions:\n",
        "        population = 1_000_000 + np.random.randint(-100000, 100000)\n",
        "        for year in years:\n",
        "            pop_growth_rate = np.random.normal(0.015, 0.005)\n",
        "            population *= (1 + pop_growth_rate)\n",
        "\n",
        "            # Agri yield set to realistic levels (tons/km²)\n",
        "            base_yield = 50 + np.random.normal(0, 5)  # Base yield: 50 tons/km² (5 tons/hectare)\n",
        "            agri_yield = base_yield + np.sin((year - 2020)/4.5) * 3 + np.random.normal(0, 2)\n",
        "\n",
        "            base_rainfall = 1100 + hash(region) % 300\n",
        "            rainfall = base_rainfall + np.random.normal(0, 100)\n",
        "\n",
        "            energy_price = 7 + 0.15 * (year - 2025) + np.random.normal(0, 0.8)\n",
        "            solar_cost = 1500 * (0.96 ** (year - 2025)) + np.random.normal(0, 50)\n",
        "            carbon_price = 2000 + 40 * (year - 2025)\n",
        "            co2_forest = 2.0\n",
        "            total_land = 100_000\n",
        "\n",
        "            data.append([\n",
        "                year, region, population, agri_yield, rainfall, energy_price,\n",
        "                0.8, solar_cost, carbon_price, total_land, co2_forest\n",
        "            ])\n",
        "\n",
        "    df = pd.DataFrame(data, columns=[\n",
        "        \"year\", \"region\", \"population\", \"agri_yield\", \"rainfall\", \"energy_price\",\n",
        "        \"solar_efficiency\", \"solar_install_cost\", \"carbon_price\", \"total_land\",\n",
        "        \"co2_per_forest_km2\"\n",
        "    ])\n",
        "\n",
        "    cols_to_norm = [\"population\", \"agri_yield\", \"rainfall\", \"energy_price\",\n",
        "                    \"solar_install_cost\", \"carbon_price\"]\n",
        "    scaler = StandardScaler()\n",
        "    df[[f\"{col}_norm\" for col in cols_to_norm]] = scaler.fit_transform(df[cols_to_norm])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage\n",
        "df = generate_synthetic_data()\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "z3s8wqP1cSke",
        "outputId": "0739c9bb-e411-42e3-a315-e5ba917dd61f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year    region    population  agri_yield     rainfall  energy_price  \\\n",
              "0  2025  Region_1  1.034476e+06   56.213464  1466.845012      6.266539   \n",
              "1  2026  Region_1  1.039591e+06   51.236956  1237.081533      7.213865   \n",
              "2  2027  Region_1  1.055301e+06   49.797052  1318.252450      7.477663   \n",
              "3  2028  Region_1  1.071882e+06   55.031385  1319.525445      7.029902   \n",
              "4  2029  Region_1  1.077098e+06   59.883396  1219.890224      8.504183   \n",
              "\n",
              "   solar_efficiency  solar_install_cost  carbon_price  total_land  \\\n",
              "0               0.8         1493.792641          2000      100000   \n",
              "1               0.8         1432.024175          2040      100000   \n",
              "2               0.8         1344.001175          2080      100000   \n",
              "3               0.8         1422.742564          2120      100000   \n",
              "4               0.8         1292.675786          2160      100000   \n",
              "\n",
              "   co2_per_forest_km2  population_norm  agri_yield_norm  rainfall_norm  \\\n",
              "0                 2.0        -0.989762         1.125503       1.561355   \n",
              "1                 2.0        -0.951667         0.272625      -0.079796   \n",
              "2                 2.0        -0.834683         0.025853       0.499991   \n",
              "3                 2.0        -0.711207         0.922917       0.509083   \n",
              "4                 2.0        -0.672363         1.754459      -0.202590   \n",
              "\n",
              "   energy_price_norm  solar_install_cost_norm  carbon_price_norm  \n",
              "0          -1.830377                 1.924397          -1.666667  \n",
              "1          -1.168554                 1.708058          -1.533333  \n",
              "2          -0.984259                 1.399765          -1.400000  \n",
              "3          -1.297075                 1.675550          -1.266667  \n",
              "4          -0.267111                 1.220002          -1.133333  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3502a5da-cd9d-428a-b7e6-18535e6e4334\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>region</th>\n",
              "      <th>population</th>\n",
              "      <th>agri_yield</th>\n",
              "      <th>rainfall</th>\n",
              "      <th>energy_price</th>\n",
              "      <th>solar_efficiency</th>\n",
              "      <th>solar_install_cost</th>\n",
              "      <th>carbon_price</th>\n",
              "      <th>total_land</th>\n",
              "      <th>co2_per_forest_km2</th>\n",
              "      <th>population_norm</th>\n",
              "      <th>agri_yield_norm</th>\n",
              "      <th>rainfall_norm</th>\n",
              "      <th>energy_price_norm</th>\n",
              "      <th>solar_install_cost_norm</th>\n",
              "      <th>carbon_price_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025</td>\n",
              "      <td>Region_1</td>\n",
              "      <td>1.034476e+06</td>\n",
              "      <td>56.213464</td>\n",
              "      <td>1466.845012</td>\n",
              "      <td>6.266539</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1493.792641</td>\n",
              "      <td>2000</td>\n",
              "      <td>100000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.989762</td>\n",
              "      <td>1.125503</td>\n",
              "      <td>1.561355</td>\n",
              "      <td>-1.830377</td>\n",
              "      <td>1.924397</td>\n",
              "      <td>-1.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2026</td>\n",
              "      <td>Region_1</td>\n",
              "      <td>1.039591e+06</td>\n",
              "      <td>51.236956</td>\n",
              "      <td>1237.081533</td>\n",
              "      <td>7.213865</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1432.024175</td>\n",
              "      <td>2040</td>\n",
              "      <td>100000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.951667</td>\n",
              "      <td>0.272625</td>\n",
              "      <td>-0.079796</td>\n",
              "      <td>-1.168554</td>\n",
              "      <td>1.708058</td>\n",
              "      <td>-1.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2027</td>\n",
              "      <td>Region_1</td>\n",
              "      <td>1.055301e+06</td>\n",
              "      <td>49.797052</td>\n",
              "      <td>1318.252450</td>\n",
              "      <td>7.477663</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1344.001175</td>\n",
              "      <td>2080</td>\n",
              "      <td>100000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.834683</td>\n",
              "      <td>0.025853</td>\n",
              "      <td>0.499991</td>\n",
              "      <td>-0.984259</td>\n",
              "      <td>1.399765</td>\n",
              "      <td>-1.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2028</td>\n",
              "      <td>Region_1</td>\n",
              "      <td>1.071882e+06</td>\n",
              "      <td>55.031385</td>\n",
              "      <td>1319.525445</td>\n",
              "      <td>7.029902</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1422.742564</td>\n",
              "      <td>2120</td>\n",
              "      <td>100000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.711207</td>\n",
              "      <td>0.922917</td>\n",
              "      <td>0.509083</td>\n",
              "      <td>-1.297075</td>\n",
              "      <td>1.675550</td>\n",
              "      <td>-1.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2029</td>\n",
              "      <td>Region_1</td>\n",
              "      <td>1.077098e+06</td>\n",
              "      <td>59.883396</td>\n",
              "      <td>1219.890224</td>\n",
              "      <td>8.504183</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1292.675786</td>\n",
              "      <td>2160</td>\n",
              "      <td>100000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.672363</td>\n",
              "      <td>1.754459</td>\n",
              "      <td>-0.202590</td>\n",
              "      <td>-0.267111</td>\n",
              "      <td>1.220002</td>\n",
              "      <td>-1.133333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3502a5da-cd9d-428a-b7e6-18535e6e4334')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3502a5da-cd9d-428a-b7e6-18535e6e4334 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3502a5da-cd9d-428a-b7e6-18535e6e4334');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2f01bb8e-d6de-4ec2-a7a5-cef642a68bfd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f01bb8e-d6de-4ec2-a7a5-cef642a68bfd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2f01bb8e-d6de-4ec2-a7a5-cef642a68bfd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 130,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 2025,\n        \"max\": 2050,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          2033,\n          2041,\n          2025\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Region_2\",\n          \"Region_5\",\n          \"Region_3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 134806.42378755767,\n        \"min\": 934102.3216966692,\n        \"max\": 1454506.7090262012,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          1014680.4070177872,\n          1193384.9976649403,\n          1319248.5841950674\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agri_yield\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.857529751640572,\n        \"min\": 35.45009713498729,\n        \"max\": 61.74750924227523,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          51.91293108396695,\n          45.96798991854338,\n          53.84774779910563\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rainfall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 140.54301612631392,\n        \"min\": 887.8864690992115,\n        \"max\": 1595.6010091272042,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          1336.4720998001008,\n          1264.5182752605267,\n          1327.262355441484\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"energy_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.436927640741803,\n        \"min\": 6.064000841122402,\n        \"max\": 11.997071840742494,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          6.767392046369618,\n          10.348304112906304,\n          10.504298809773251\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"solar_efficiency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8946804424023266e-15,\n        \"min\": 0.8,\n        \"max\": 0.8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"solar_install_cost\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 286.62171632158885,\n        \"min\": 472.01560630087084,\n        \"max\": 1626.9581358134667,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          1326.3899726147451\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"carbon_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 301,\n        \"min\": 2000,\n        \"max\": 3000,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          2320\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_land\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 100000,\n        \"max\": 100000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          100000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"co2_per_forest_km2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 2.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0038684863987395,\n        \"min\": -1.7372170765122907,\n        \"max\": 2.1380994695822917,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          -1.1371729667768824\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agri_yield_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0038684863987395,\n        \"min\": -2.4329406284733626,\n        \"max\": 2.0739324746386063,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          0.3884740119844621\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rainfall_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0038684863987397,\n        \"min\": -2.574020881246341,\n        \"max\": 2.481031612160786,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          0.6301296381021044\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"energy_price_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0038684863987395,\n        \"min\": -1.9718742148982935,\n        \"max\": 2.173096509591442,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          -1.4804700240837976\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"solar_install_cost_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0038684863987393,\n        \"min\": -1.6542913724837736,\n        \"max\": 2.390797826823392,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          1.3380830816803246\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"carbon_price_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0038684863987395,\n        \"min\": -1.6666666666666667,\n        \"max\": 1.6666666666666667,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          -0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Agents and Logging"
      ],
      "metadata": {
        "id": "DUSmjmyenyDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Baseline Agents"
      ],
      "metadata": {
        "id": "c-zqHwrj43iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define list of baseline policies\n",
        "def equal_policy(obs):\n",
        "    return np.array([1/3, 1/3, 1/3], dtype=np.float32)\n",
        "\n",
        "def agri_max_policy(obs):\n",
        "    agri = 1 - 0.33  # Keep forest at min constraint\n",
        "    return np.array([agri, 0.33, 0.0], dtype=np.float32)\n",
        "\n",
        "def solar_max_policy(obs):\n",
        "    solar = 1 - 0.33\n",
        "    return np.array([0.0, 0.33, solar], dtype=np.float32)\n",
        "\n",
        "def random_valid_policy(obs):\n",
        "    forest = 0.33 + np.random.rand() * 0.3  # 0.33 to 0.63\n",
        "    remaining = 1 - forest\n",
        "    agri = np.random.rand()\n",
        "    solar = 1 - agri\n",
        "    agri, solar = agri * remaining, solar * remaining\n",
        "    return np.array([agri, forest, solar], dtype=np.float32)\n",
        "\n",
        "baseline_policies = {\n",
        "    \"Equal Allocation\": equal_policy,\n",
        "    \"Agri Maximization\": agri_max_policy,\n",
        "    \"Solar Maximization\": solar_max_policy,\n",
        "    \"Random Feasible\": random_valid_policy,\n",
        "}\n",
        "\n",
        "# Run simulation for each baseline\n",
        "results = {}\n",
        "region_list = sorted(df[\"region\"].unique())\n",
        "env = LandUseOptimizationEnv(df, region_list)\n",
        "\n",
        "for name, policy_fn in baseline_policies.items():\n",
        "    total_rewards = []\n",
        "    agri_shares = []\n",
        "    for _ in range(5):  # 5 episodes for smoothing\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        ep_reward = 0\n",
        "        while not done:\n",
        "            action = policy_fn(obs)\n",
        "            obs, reward, done, info = env.step(action)\n",
        "            ep_reward += reward\n",
        "            agri_shares.append(info.get(\"agri_share\", np.nan))  # new logging\n",
        "        total_rewards.append(ep_reward)\n",
        "    avg_reward = np.mean(total_rewards)\n",
        "    results[name] = avg_reward\n",
        "\n",
        "# Display results\n",
        "print(\"Baseline Results:\")\n",
        "for k, v in results.items():\n",
        "    print(f\"{k:20s}: Avg Total Reward = {v:.2f}\")\n",
        "\n",
        "# Bar plot of rewards\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(results.keys(), results.values(), color='skyblue')\n",
        "plt.ylabel(\"Average Total Reward (over 5 episodes)\")\n",
        "plt.title(\"Baseline Agent Performance Comparison\")\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "opRZMZ5mdLst",
        "outputId": "16e1af24-8e5b-4053-87ab-3a142ad47d97"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2785396083>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mep_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0magri_shares\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"agri_share\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# new logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logging Baseline Results"
      ],
      "metadata": {
        "id": "Ka3f94rWq0h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_policy_with_logging(policy_fn, env, episodes=5):\n",
        "    logs = []\n",
        "\n",
        "    for ep in range(episodes):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        ep_log = {\n",
        "            \"reward\": 0,\n",
        "            \"food_sufficiency\": [],\n",
        "            \"forest_cover\": [],\n",
        "            \"co2_reduction\": [],\n",
        "            \"agri_share\": [],\n",
        "            \"rolling_penalty\": [],\n",
        "            \"constraint_violated\": [],\n",
        "            \"years\": [],\n",
        "        }\n",
        "\n",
        "        while not done:\n",
        "            action = policy_fn(obs)\n",
        "            obs, reward, done, info = env.step(action)\n",
        "\n",
        "            ep_log[\"reward\"] += reward\n",
        "            ep_log[\"food_sufficiency\"].append(min(info[\"food_production\"] / info[\"food_required\"], 1.0))\n",
        "            ep_log[\"forest_cover\"].append(info[\"forest_share\"])\n",
        "            ep_log[\"co2_reduction\"].append(info[\"co2_reduction\"])\n",
        "            ep_log[\"agri_share\"].append(info.get(\"agri_share\", np.nan))\n",
        "            ep_log[\"rolling_penalty\"].append(info.get(\"rolling_agri_penalty\", 0.0))\n",
        "            ep_log[\"constraint_violated\"].append(info.get(\"constraint_violated\", False))\n",
        "            ep_log[\"years\"].append(info[\"year\"])\n",
        "\n",
        "        logs.append(ep_log)\n",
        "\n",
        "    return logs\n",
        "\n",
        "\n",
        "# Run logging for each policy\n",
        "baseline_logs = {}\n",
        "for name, policy_fn in baseline_policies.items():\n",
        "    print(f\"Running detailed evaluation for: {name}\")\n",
        "    baseline_logs[name] = evaluate_policy_with_logging(policy_fn, env, episodes=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHriJC3ipn8b",
        "outputId": "397b0d00-e146-474c-860a-ab24b42dd03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running detailed evaluation for: Equal Allocation\n",
            "Running detailed evaluation for: Agri Maximization\n",
            "Running detailed evaluation for: Solar Maximization\n",
            "Running detailed evaluation for: Random Feasible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dashboard and Summary Statistics"
      ],
      "metadata": {
        "id": "wGAAOn515EaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import necessary libraries after kernel reset\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Define plotting function again after reset\n",
        "def plot_baseline_dashboard(baseline_logs):\n",
        "    metrics = [\"food_sufficiency\", \"forest_cover\", \"co2_reduction\"]\n",
        "    metric_titles = {\n",
        "        \"food_sufficiency\": \"Food Sufficiency (≤ 1.0)\",\n",
        "        \"forest_cover\": \"Forest Share\",\n",
        "        \"co2_reduction\": \"CO₂ Reduction (tons)\"\n",
        "    }\n",
        "\n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=1,\n",
        "        subplot_titles=[metric_titles[m] for m in metrics],\n",
        "        shared_xaxes=True,\n",
        "        vertical_spacing=0.08\n",
        "    )\n",
        "\n",
        "    color_palette = {\n",
        "        \"Equal Allocation\": \"blue\",\n",
        "        \"Agri Maximization\": \"green\",\n",
        "        \"Solar Maximization\": \"orange\",\n",
        "        \"Random Feasible\": \"purple\"\n",
        "    }\n",
        "\n",
        "    for i, metric in enumerate(metrics, start=1):\n",
        "        for policy, logs in baseline_logs.items():\n",
        "            for ep_idx, ep in enumerate(logs):\n",
        "                y_vals = ep.get(metric, [])\n",
        "                x_vals = list(range(len(y_vals)))\n",
        "                fig.add_trace(\n",
        "                    go.Scatter(\n",
        "                        x=x_vals, y=y_vals,\n",
        "                        mode='lines+markers',\n",
        "                        name=f\"{policy} - Ep{ep_idx+1}\",\n",
        "                        line=dict(color=color_palette.get(policy, None)),\n",
        "                        showlegend=(i == 1)\n",
        "                    ),\n",
        "                    row=i, col=1\n",
        "                )\n",
        "\n",
        "    fig.update_layout(\n",
        "        height=900,\n",
        "        title_text=\"📊 Baseline Policy Performance per Region\",\n",
        "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
        "        margin=dict(t=100, b=50)\n",
        "    )\n",
        "    fig.update_xaxes(title_text=\"Year Index (t)\", row=3, col=1)\n",
        "    return fig\n",
        "\n",
        "# Show the dashboard\n",
        "fig = plot_baseline_dashboard(baseline_logs)\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "PyXgkHEFubg3",
        "outputId": "db683a64-60e9-417b-adc0-516a1cfb0d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"42941652-0dbc-4913-8c9a-f580ad27f23b\" class=\"plotly-graph-div\" style=\"height:900px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"42941652-0dbc-4913-8c9a-f580ad27f23b\")) {                    Plotly.newPlot(                        \"42941652-0dbc-4913-8c9a-f580ad27f23b\",                        [{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Equal Allocation - Ep1\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.06307453577714901,0.05059775752759915,0.054436606718042596,0.05862201284520751,0.05035711352307586,0.052014905192788,0.0521645598402693,0.04345493846238889,0.04863387893663791,0.04467578724378326,0.043462400619265845,0.03561011264887494,0.03646243029327169,0.035070996672260255,0.03401511986595091,0.027786321317932003,0.031375382587810766,0.024655797322031554,0.031105735259298068,0.03108568591229048,0.03549484309716469,0.03461368969279171,0.027640795106131974,0.02754852193657347,0.03557852683945696,0.028526164319485483],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Equal Allocation - Ep2\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.06307453577714901,0.05059775752759915,0.054436606718042596,0.05862201284520751,0.05035711352307586,0.052014905192788,0.0521645598402693,0.04345493846238889,0.04863387893663791,0.04467578724378326,0.043462400619265845,0.03561011264887494,0.03646243029327169,0.035070996672260255,0.03401511986595091,0.027786321317932003,0.031375382587810766,0.024655797322031554,0.031105735259298068,0.03108568591229048,0.03549484309716469,0.03461368969279171,0.027640795106131974,0.02754852193657347,0.03557852683945696,0.028526164319485483],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Equal Allocation - Ep3\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.06307453577714901,0.05059775752759915,0.054436606718042596,0.05862201284520751,0.05035711352307586,0.052014905192788,0.0521645598402693,0.04345493846238889,0.04863387893663791,0.04467578724378326,0.043462400619265845,0.03561011264887494,0.03646243029327169,0.035070996672260255,0.03401511986595091,0.027786321317932003,0.031375382587810766,0.024655797322031554,0.031105735259298068,0.03108568591229048,0.03549484309716469,0.03461368969279171,0.027640795106131974,0.02754852193657347,0.03557852683945696,0.028526164319485483],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"Agri Maximization - Ep1\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.12677981629174623,0.1017014921328572,0.10941757896789434,0.11783024524233332,0.10121779768613205,0.10454995892594945,0.10485076476591504,0.08734442588203252,0.09775409618433936,0.08979833192062842,0.08735942481728182,0.0715763260740215,0.07328948453087664,0.07049270296632806,0.06837039059603058,0.05585050557577135,0.06306451869293009,0.04955815237479942,0.06252252756527148,0.062482228377983416,0.07134463427621755,0.06957351594209378,0.0555579978914845,0.0553725288215794,0.071512838597402,0.057337590001617665],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"Agri Maximization - Ep2\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.12677981629174623,0.1017014921328572,0.10941757896789434,0.11783024524233332,0.10121779768613205,0.10454995892594945,0.10485076476591504,0.08734442588203252,0.09775409618433936,0.08979833192062842,0.08735942481728182,0.0715763260740215,0.07328948453087664,0.07049270296632806,0.06837039059603058,0.05585050557577135,0.06306451869293009,0.04955815237479942,0.06252252756527148,0.062482228377983416,0.07134463427621755,0.06957351594209378,0.0555579978914845,0.0553725288215794,0.071512838597402,0.057337590001617665],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"Agri Maximization - Ep3\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.12677981629174623,0.1017014921328572,0.10941757896789434,0.11783024524233332,0.10121779768613205,0.10454995892594945,0.10485076476591504,0.08734442588203252,0.09775409618433936,0.08979833192062842,0.08735942481728182,0.0715763260740215,0.07328948453087664,0.07049270296632806,0.06837039059603058,0.05585050557577135,0.06306451869293009,0.04955815237479942,0.06252252756527148,0.062482228377983416,0.07134463427621755,0.06957351594209378,0.0555579978914845,0.0553725288215794,0.071512838597402,0.057337590001617665],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"orange\"},\"mode\":\"lines+markers\",\"name\":\"Solar Maximization - Ep1\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"orange\"},\"mode\":\"lines+markers\",\"name\":\"Solar Maximization - Ep2\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"orange\"},\"mode\":\"lines+markers\",\"name\":\"Solar Maximization - Ep3\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"purple\"},\"mode\":\"lines+markers\",\"name\":\"Random Feasible - Ep1\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.07898084343005429,0.042026035900553996,0.00014125733570475256,0.06634317341618826,0.08661904855362323,0.06156162690100131,0.04458116446627146,0.04993311279064831,0.06635237223468202,0.023613773383183167,0.02394678267721031,0.03288460833827503,0.026430729020781293,0.007588314509755699,0.010004241604995776,0.03288445836223201,0.022334269558814804,0.030889811853107674,0.027493813074361804,0.02135850192945781,0.02741614059253659,0.03330726619789021,0.023415940007629962,0.002366745272726931,0.050350856744916565,0.0036454121034715336],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"purple\"},\"mode\":\"lines+markers\",\"name\":\"Random Feasible - Ep2\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.08271152982412108,0.01693044729764987,0.040777820035807065,0.0662672439167905,0.08606200887601678,0.03847571046178205,0.040697761006136174,0.034170176497895464,0.05844239580688178,0.06704617670911128,0.017100676371951548,0.020839788032449666,0.028195568178067124,0.027119234200819735,0.05529318223663813,0.035831562415593064,0.02612643222468698,0.007903132751237127,0.008067986526754535,0.01868924973366857,0.00665392304354879,0.05837709015088087,0.01789549681552937,0.007001173070609669,0.007268566948314741,0.013292750260661167],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"purple\"},\"mode\":\"lines+markers\",\"name\":\"Random Feasible - Ep3\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.050009246832975994,0.08105785536348714,0.007294082240087111,0.013007676624066355,0.09689526991853895,0.06697864878639569,0.043866150461604615,0.01994045618910147,0.021745270417563096,0.04009727049395863,0.040813492543935626,0.011720523224562787,0.025078119517891455,0.038055483879297025,0.005684525892830756,0.007343983608725265,0.030096802220574696,0.01397462734151889,0.018612755888239567,0.006220668392617648,0.03135667741902459,0.005469645313666004,0.024447560843447767,0.021368632580358236,0.05243145480773331,0.002496407374243361],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Equal Allocation - Ep1\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Equal Allocation - Ep2\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Equal Allocation - Ep3\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408,0.3333333432674408],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"Agri Maximization - Ep1\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"Agri Maximization - Ep2\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"Agri Maximization - Ep3\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"orange\"},\"mode\":\"lines+markers\",\"name\":\"Solar Maximization - Ep1\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"orange\"},\"mode\":\"lines+markers\",\"name\":\"Solar Maximization - Ep2\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"orange\"},\"mode\":\"lines+markers\",\"name\":\"Solar Maximization - Ep3\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185,0.33000001311302185],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"purple\"},\"mode\":\"lines+markers\",\"name\":\"Random Feasible - Ep1\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.41901829838752747,0.6162099242210388,0.5888641476631165,0.545271635055542,0.34216761589050293,0.4070082902908325,0.5701064467430115,0.3576854467391968,0.49487510323524475,0.4512719213962555,0.554955244064331,0.5238288640975952,0.5964117050170898,0.4806460738182068,0.36472126841545105,0.3815545439720154,0.5522943735122681,0.5787053108215332,0.5760037899017334,0.4897478222846985,0.35531771183013916,0.6030403971672058,0.3948154151439667,0.575016975402832,0.44621777534484863,0.45116937160491943],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"purple\"},\"mode\":\"lines+markers\",\"name\":\"Random Feasible - Ep2\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.4927603006362915,0.5070856809616089,0.44527187943458557,0.5037798881530762,0.35966208577156067,0.33369290828704834,0.3382260799407959,0.4877437651157379,0.3796885013580322,0.34343352913856506,0.6139933466911316,0.4851718246936798,0.3320131301879883,0.5675160884857178,0.3603779673576355,0.489325612783432,0.5040664672851562,0.36157774925231934,0.6216076016426086,0.6232356429100037,0.3707367181777954,0.3926592171192169,0.45424506068229675,0.423961877822876,0.4763553738594055,0.5806440711021423],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"purple\"},\"mode\":\"lines+markers\",\"name\":\"Random Feasible - Ep3\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[0.44244107604026794,0.46323832869529724,0.4936143457889557,0.512063205242157,0.339281290769577,0.5620616674423218,0.4733635485172272,0.3805010914802551,0.5815647840499878,0.5780445337295532,0.38315126299858093,0.5332161784172058,0.5792065262794495,0.37957262992858887,0.6299141645431519,0.5750271081924438,0.5647165179252625,0.4201468229293823,0.5677564144134521,0.5492454171180725,0.5857673287391663,0.6020828485488892,0.5079043507575989,0.43603822588920593,0.34139445424079895,0.4947967529296875],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Equal Allocation - Ep1\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[53400001.59144402,54466668.28989983,55533334.988355644,56600001.686811455,57666668.385267265,58733335.083723076,59800001.782178886,60866668.4806347,61933335.17909051,63000001.87754632,64066668.57600213,65133335.27445794,66200001.97291375,67266668.67136957,68333335.36982538,69400002.06828119,70466668.766737,71533335.46519281,72600002.16364862,73666668.86210443,74733335.56056024,75800002.25901605,76866668.95747186,77933335.65592767,79000002.35438348,80066669.0528393],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Equal Allocation - Ep2\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[53400001.59144402,54466668.28989983,55533334.988355644,56600001.686811455,57666668.385267265,58733335.083723076,59800001.782178886,60866668.4806347,61933335.17909051,63000001.87754632,64066668.57600213,65133335.27445794,66200001.97291375,67266668.67136957,68333335.36982538,69400002.06828119,70466668.766737,71533335.46519281,72600002.16364862,73666668.86210443,74733335.56056024,75800002.25901605,76866668.95747186,77933335.65592767,79000002.35438348,80066669.0528393],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Equal Allocation - Ep3\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[53400001.59144402,54466668.28989983,55533334.988355644,56600001.686811455,57666668.385267265,58733335.083723076,59800001.782178886,60866668.4806347,61933335.17909051,63000001.87754632,64066668.57600213,65133335.27445794,66200001.97291375,67266668.67136957,68333335.36982538,69400002.06828119,70466668.766737,71533335.46519281,72600002.16364862,73666668.86210443,74733335.56056024,75800002.25901605,76866668.95747186,77933335.65592767,79000002.35438348,80066669.0528393],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"Agri Maximization - Ep1\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"Agri Maximization - Ep2\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"Agri Maximization - Ep3\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437,66000.00262260437],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"orange\"},\"mode\":\"lines+markers\",\"name\":\"Solar Maximization - Ep1\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[107266002.67291069,109410002.72631645,111554002.77972221,113698002.83312798,115842002.88653374,117986002.9399395,120130002.99334526,122274003.04675102,124418003.10015678,126562003.15356255,128706003.20696831,130850003.26037407,132994003.31377983,135138003.3671856,137282003.42059135,139426003.47399712,141570003.52740288,143714003.58080864,145858003.6342144,148002003.68762016,150146003.74102592,152290003.7944317,154434003.84783745,156578003.9012432,158722003.95464897,160866004.00805473],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"orange\"},\"mode\":\"lines+markers\",\"name\":\"Solar Maximization - Ep2\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[107266002.67291069,109410002.72631645,111554002.77972221,113698002.83312798,115842002.88653374,117986002.9399395,120130002.99334526,122274003.04675102,124418003.10015678,126562003.15356255,128706003.20696831,130850003.26037407,132994003.31377983,135138003.3671856,137282003.42059135,139426003.47399712,141570003.52740288,143714003.58080864,145858003.6342144,148002003.68762016,150146003.74102592,152290003.7944317,154434003.84783745,156578003.9012432,158722003.95464897,160866004.00805473],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"orange\"},\"mode\":\"lines+markers\",\"name\":\"Solar Maximization - Ep3\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[107266002.67291069,109410002.72631645,111554002.77972221,113698002.83312798,115842002.88653374,117986002.9399395,120130002.99334526,122274003.04675102,124418003.10015678,126562003.15356255,128706003.20696831,130850003.26037407,132994003.31377983,135138003.3671856,137282003.42059135,139426003.47399712,141570003.52740288,143714003.58080864,145858003.6342144,148002003.68762016,150146003.74102592,152290003.7944317,154434003.84783745,156578003.9012432,158722003.95464897,160866004.00805473],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"purple\"},\"mode\":\"lines+markers\",\"name\":\"Random Feasible - Ep1\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[26257798.200845722,17573634.755611423,68386845.5529213,13251591.15791321,14664360.95237732,35013710.33191682,26101307.66630173,47365773.94008637,9443974.286317827,70426160.3176594,50297058.62998963,32966737.389564514,32252750.587463383,90257807.62434007,110100007.24196434,46658589.39886093,44552311.06281281,904895.1663076879,28265834.760665894,62192191.75577164,86807521.36707307,17434898.746013645,74452257.15041162,92701366.99676515,19518135.59532166,121586234.16423799],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"purple\"},\"mode\":\"lines+markers\",\"name\":\"Random Feasible - Ep2\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[11319302.868843079,62342325.3774643,50846386.605501175,20353515.98262787,12281978.279352188,73940730.54790497,72054761.45744325,45723858.72006416,40861767.625808716,29582657.748460773,49054696.786403656,62513109.11774635,81455593.29986572,35338735.34202576,20095975.43478012,16910052.675008774,46219557.666778564,114042230.74913025,63649324.95355606,39064628.303051,127031979.68006134,10339675.050973892,76110114.75920677,114858289.38484192,107968519.55652237,63482787.50181199],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"line\":{\"color\":\"purple\"},\"mode\":\"lines+markers\",\"name\":\"Random Feasible - Ep3\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\"y\":[47012073.15325737,543086.7053568363,76929196.95973396,70312274.49178697,3408288.5921001434,1645554.393529892,44237052.85191536,85173003.25632095,50115951.895713806,23297089.529037476,58412195.81961632,69807143.34249498,38116094.79188919,52235454.79774475,64511004.80556488,70184427.18982698,24513692.65317917,83898053.3361435,50767940.473556526,84908104.81309892,26943616.926670074,78559837.65125276,45552823.69852067,71429639.47653772,39703384.21463967,114346708.20236206],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"matches\":\"x3\",\"showticklabels\":false},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.72,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0],\"matches\":\"x3\",\"showticklabels\":false},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.36,0.6399999999999999]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Year Index (t)\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.27999999999999997]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Food Sufficiency (≤ 1.0)\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Forest Share\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.6399999999999999,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"CO₂ Reduction (tons)\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.27999999999999997,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"📊 Baseline Policy Performance per Region\"},\"legend\":{\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"margin\":{\"t\":100,\"b\":50},\"height\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('42941652-0dbc-4913-8c9a-f580ad27f23b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Compute summary stats\n",
        "summary_data = []\n",
        "\n",
        "for policy, episodes in baseline_logs.items():\n",
        "    rewards = []\n",
        "    avg_food = []\n",
        "    std_forest = []\n",
        "    co2_delta = []\n",
        "    for ep in episodes:\n",
        "        rewards.append(ep[\"reward\"])\n",
        "        avg_food.append(np.mean(ep[\"food_sufficiency\"]))\n",
        "        std_forest.append(np.std(ep[\"forest_cover\"]))\n",
        "        co2_delta.append(ep[\"co2_reduction\"][-1] - ep[\"co2_reduction\"][0])\n",
        "    summary_data.append({\n",
        "        \"Policy\": policy,\n",
        "        \"Avg Reward\": round(np.mean(rewards), 1),\n",
        "        \"Avg Food Sufficiency\": round(np.mean(avg_food), 2),\n",
        "        \"Std Dev Forest Share\": round(np.mean(std_forest), 3),\n",
        "        \"CO₂ Change (tons)\": round(np.mean(co2_delta), 1)\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "# Display table using Plotly\n",
        "fig_summary = go.Figure(data=[go.Table(\n",
        "    header=dict(values=list(summary_df.columns),\n",
        "                fill_color='lightgrey',\n",
        "                align='center'),\n",
        "    cells=dict(values=[summary_df[col] for col in summary_df.columns],\n",
        "               fill_color='white',\n",
        "               align='center'))\n",
        "])\n",
        "\n",
        "fig_summary.update_layout(title=\"📋 Baseline Policy Summary Statistics\", height=350)\n",
        "fig_summary.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "IDSrT8sAvEcH",
        "outputId": "44aad1b0-6be9-4fa4-9450-eaf5a9f09bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3c0dbba2-2267-47a9-a84c-b26d56f18ae8\" class=\"plotly-graph-div\" style=\"height:350px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3c0dbba2-2267-47a9-a84c-b26d56f18ae8\")) {                    Plotly.newPlot(                        \"3c0dbba2-2267-47a9-a84c-b26d56f18ae8\",                        [{\"cells\":{\"align\":\"center\",\"fill\":{\"color\":\"white\"},\"values\":[[\"Equal Allocation\",\"Agri Maximization\",\"Solar Maximization\",\"Random Feasible\"],[173363.3,649.1,347322.5,135172.4],[0.04,0.08,0.0,0.03],[0.0,0.0,0.0,0.08799999952316284],[26666667.5,0.0,53600001.3,71608851.9]]},\"header\":{\"align\":\"center\",\"fill\":{\"color\":\"lightgrey\"},\"values\":[\"Policy\",\"Avg Reward\",\"Avg Food Sufficiency\",\"Std Dev Forest Share\",\"CO₂ Change (tons)\"]},\"type\":\"table\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"📋 Baseline Policy Summary Statistics\"},\"height\":350},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3c0dbba2-2267-47a9-a84c-b26d56f18ae8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQyGvCJW4lhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining RL Agent using PPO Model"
      ],
      "metadata": {
        "id": "CFvVvef_53zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "# Check environment compatibility (optional)\n",
        "env = LandUseOptimizationEnv(df, region_list, forecast_years=25)  # Explicitly pass forecast_years\n",
        "check_env(env, warn=True)\n",
        "\n",
        "# Wrap in DummyVecEnv\n",
        "vec_env = DummyVecEnv([lambda: LandUseOptimizationEnv(df, region_list, forecast_years=25)])  # Include forecast_years in lambda"
      ],
      "metadata": {
        "id": "TkLgYQWib2Ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c35ef29-f357-4114-c8d0-d74d2a671273"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/env_checker.py:462: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
        "model.learn(total_timesteps=100_000)\n",
        "model.save('ppo_landuse_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGEEFBbmdK11",
        "outputId": "bd581322-3f1d-4b01-9533-dc8bfedb8caf",
        "collapsed": true
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 466  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048099756 |\n",
            "|    clip_fraction        | 0.022        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.25        |\n",
            "|    explained_variance   | -0.00432     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.3e+05      |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00489     |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 2.52e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 371         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005309158 |\n",
            "|    clip_fraction        | 0.0298      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.24       |\n",
            "|    explained_variance   | 0.00688     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.12e+05    |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00689    |\n",
            "|    std                  | 0.995       |\n",
            "|    value_loss           | 2.6e+05     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004728603 |\n",
            "|    clip_fraction        | 0.0351      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.25       |\n",
            "|    explained_variance   | 0.00129     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.24e+05    |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00714    |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 2.56e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 356         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 28          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004878978 |\n",
            "|    clip_fraction        | 0.0167      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.24       |\n",
            "|    explained_variance   | 0.000591    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.24e+05    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00386    |\n",
            "|    std                  | 0.993       |\n",
            "|    value_loss           | 2.75e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 35           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039163553 |\n",
            "|    clip_fraction        | 0.0184       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.23        |\n",
            "|    explained_variance   | 0.000309     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.12e+05     |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00472     |\n",
            "|    std                  | 0.991        |\n",
            "|    value_loss           | 2.63e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 40           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062743183 |\n",
            "|    clip_fraction        | 0.0417       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.23        |\n",
            "|    explained_variance   | 0.000238     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.33e+05     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00693     |\n",
            "|    std                  | 0.989        |\n",
            "|    value_loss           | 2.67e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 348          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 47           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036422801 |\n",
            "|    clip_fraction        | 0.0158       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.22        |\n",
            "|    explained_variance   | 0.000148     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.46e+05     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00356     |\n",
            "|    std                  | 0.985        |\n",
            "|    value_loss           | 2.75e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 345          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 53           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059456294 |\n",
            "|    clip_fraction        | 0.0311       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.22        |\n",
            "|    explained_variance   | 8.83e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.15e+05     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00399     |\n",
            "|    std                  | 0.991        |\n",
            "|    value_loss           | 2.6e+05      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 344         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 59          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005729232 |\n",
            "|    clip_fraction        | 0.0367      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.22       |\n",
            "|    explained_variance   | 7.69e-05    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.39e+05    |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00711    |\n",
            "|    std                  | 0.987       |\n",
            "|    value_loss           | 2.75e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 65           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042928457 |\n",
            "|    clip_fraction        | 0.0133       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.2         |\n",
            "|    explained_variance   | 6.26e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.43e+05     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00353     |\n",
            "|    std                  | 0.98         |\n",
            "|    value_loss           | 2.8e+05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 71           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037360128 |\n",
            "|    clip_fraction        | 0.0113       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.19        |\n",
            "|    explained_variance   | 4.3e-05      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.6e+05      |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00319     |\n",
            "|    std                  | 0.98         |\n",
            "|    value_loss           | 2.75e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 339          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 78           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046944143 |\n",
            "|    clip_fraction        | 0.02         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.18        |\n",
            "|    explained_variance   | 3.52e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.51e+05     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00467     |\n",
            "|    std                  | 0.973        |\n",
            "|    value_loss           | 2.75e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 84          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007216991 |\n",
            "|    clip_fraction        | 0.0475      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.16       |\n",
            "|    explained_variance   | 3.05e-05    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.23e+05    |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0083     |\n",
            "|    std                  | 0.967       |\n",
            "|    value_loss           | 2.9e+05     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 337          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 91           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048821247 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.15        |\n",
            "|    explained_variance   | 1.97e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.53e+05     |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00478     |\n",
            "|    std                  | 0.97         |\n",
            "|    value_loss           | 2.98e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 337         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 97          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005057279 |\n",
            "|    clip_fraction        | 0.0254      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.17       |\n",
            "|    explained_variance   | 1.91e-05    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.47e+05    |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00535    |\n",
            "|    std                  | 0.974       |\n",
            "|    value_loss           | 3.09e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 335          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 103          |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051982854 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.16        |\n",
            "|    explained_variance   | 1.35e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.67e+05     |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00418     |\n",
            "|    std                  | 0.966        |\n",
            "|    value_loss           | 3.06e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 334          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 110          |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073108906 |\n",
            "|    clip_fraction        | 0.053        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.14        |\n",
            "|    explained_variance   | 1.47e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.47e+05     |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00662     |\n",
            "|    std                  | 0.96         |\n",
            "|    value_loss           | 3.06e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 333         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 116         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008839029 |\n",
            "|    clip_fraction        | 0.0735      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.13       |\n",
            "|    explained_variance   | 1.17e-05    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.69e+05    |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00855    |\n",
            "|    std                  | 0.96        |\n",
            "|    value_loss           | 3.15e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 333          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 122          |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063914196 |\n",
            "|    clip_fraction        | 0.0498       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.11        |\n",
            "|    explained_variance   | 9.48e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.72e+05     |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00746     |\n",
            "|    std                  | 0.947        |\n",
            "|    value_loss           | 3.31e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 332         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 129         |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006862508 |\n",
            "|    clip_fraction        | 0.0678      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.09       |\n",
            "|    explained_variance   | 8.23e-06    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.74e+05    |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0083     |\n",
            "|    std                  | 0.95        |\n",
            "|    value_loss           | 3.38e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 332         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 135         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005480758 |\n",
            "|    clip_fraction        | 0.0242      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.08       |\n",
            "|    explained_variance   | 7.69e-06    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.78e+05    |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.00411    |\n",
            "|    std                  | 0.941       |\n",
            "|    value_loss           | 3.56e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 142          |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076528303 |\n",
            "|    clip_fraction        | 0.0622       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.07        |\n",
            "|    explained_variance   | 6.44e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.78e+05     |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00726     |\n",
            "|    std                  | 0.943        |\n",
            "|    value_loss           | 3.65e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 148          |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069227573 |\n",
            "|    clip_fraction        | 0.0583       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.07        |\n",
            "|    explained_variance   | 6.14e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.96e+05     |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.0078      |\n",
            "|    std                  | 0.937        |\n",
            "|    value_loss           | 3.78e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 154          |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063167578 |\n",
            "|    clip_fraction        | 0.0498       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.05        |\n",
            "|    explained_variance   | 5.6e-06      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.66e+05     |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00669     |\n",
            "|    std                  | 0.933        |\n",
            "|    value_loss           | 3.89e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 160          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072641014 |\n",
            "|    clip_fraction        | 0.0519       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.02        |\n",
            "|    explained_variance   | 4.23e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.84e+05     |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00803     |\n",
            "|    std                  | 0.922        |\n",
            "|    value_loss           | 4.07e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 331         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 167         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005008626 |\n",
            "|    clip_fraction        | 0.0351      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4          |\n",
            "|    explained_variance   | 4.23e-06    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.05e+05    |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00516    |\n",
            "|    std                  | 0.917       |\n",
            "|    value_loss           | 4.16e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 172          |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060454356 |\n",
            "|    clip_fraction        | 0.0471       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.98        |\n",
            "|    explained_variance   | 4.95e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.52e+05     |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.00701     |\n",
            "|    std                  | 0.913        |\n",
            "|    value_loss           | 4.23e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 179          |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020254222 |\n",
            "|    clip_fraction        | 0.00483      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.97        |\n",
            "|    explained_variance   | 5.48e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.6e+05      |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00257     |\n",
            "|    std                  | 0.904        |\n",
            "|    value_loss           | 4.35e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 332          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 185          |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059466846 |\n",
            "|    clip_fraction        | 0.0328       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.94        |\n",
            "|    explained_variance   | 6.91e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.46e+05     |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.00592     |\n",
            "|    std                  | 0.894        |\n",
            "|    value_loss           | 4.32e+05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 331        |\n",
            "|    iterations           | 31         |\n",
            "|    time_elapsed         | 191        |\n",
            "|    total_timesteps      | 63488      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00428542 |\n",
            "|    clip_fraction        | 0.0179     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.9       |\n",
            "|    explained_variance   | 1.25e-05   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.01e+05   |\n",
            "|    n_updates            | 300        |\n",
            "|    policy_gradient_loss | -0.00409   |\n",
            "|    std                  | 0.883      |\n",
            "|    value_loss           | 4.38e+05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 197          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049395575 |\n",
            "|    clip_fraction        | 0.0215       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.87        |\n",
            "|    explained_variance   | 0.0478       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.56e+05     |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    std                  | 0.88         |\n",
            "|    value_loss           | 4.41e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 331         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 204         |\n",
            "|    total_timesteps      | 67584       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007660822 |\n",
            "|    clip_fraction        | 0.0718      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.86       |\n",
            "|    explained_variance   | 0.0538      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.18e+05    |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.00873    |\n",
            "|    std                  | 0.874       |\n",
            "|    value_loss           | 4.35e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 209          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067342985 |\n",
            "|    clip_fraction        | 0.0487       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.84        |\n",
            "|    explained_variance   | 0.0533       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.33e+05     |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00558     |\n",
            "|    std                  | 0.868        |\n",
            "|    value_loss           | 4.49e+05     |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 331       |\n",
            "|    iterations           | 35        |\n",
            "|    time_elapsed         | 216       |\n",
            "|    total_timesteps      | 71680     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0053597 |\n",
            "|    clip_fraction        | 0.04      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.84     |\n",
            "|    explained_variance   | 0.0573    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.16e+05  |\n",
            "|    n_updates            | 340       |\n",
            "|    policy_gradient_loss | -0.00477  |\n",
            "|    std                  | 0.872     |\n",
            "|    value_loss           | 4.55e+05  |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 222          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043488843 |\n",
            "|    clip_fraction        | 0.0279       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.83        |\n",
            "|    explained_variance   | 0.0597       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.92e+05     |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00557     |\n",
            "|    std                  | 0.866        |\n",
            "|    value_loss           | 4.71e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 331         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 228         |\n",
            "|    total_timesteps      | 75776       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005905954 |\n",
            "|    clip_fraction        | 0.0417      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.81       |\n",
            "|    explained_variance   | 0.0594      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.16e+05    |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -0.00665    |\n",
            "|    std                  | 0.861       |\n",
            "|    value_loss           | 4.66e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 234          |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046716994 |\n",
            "|    clip_fraction        | 0.0305       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.8         |\n",
            "|    explained_variance   | 0.0609       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.55e+05     |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00486     |\n",
            "|    std                  | 0.859        |\n",
            "|    value_loss           | 4.75e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 241          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035664185 |\n",
            "|    clip_fraction        | 0.0147       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.8         |\n",
            "|    explained_variance   | 0.0618       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.7e+05      |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.00276     |\n",
            "|    std                  | 0.86         |\n",
            "|    value_loss           | 4.61e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 246          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074455356 |\n",
            "|    clip_fraction        | 0.0595       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.79        |\n",
            "|    explained_variance   | 0.0634       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.24e+05     |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00684     |\n",
            "|    std                  | 0.854        |\n",
            "|    value_loss           | 4.55e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 253          |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035715448 |\n",
            "|    clip_fraction        | 0.0128       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.78        |\n",
            "|    explained_variance   | 0.0665       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.51e+05     |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00244     |\n",
            "|    std                  | 0.856        |\n",
            "|    value_loss           | 4.7e+05      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 331         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 259         |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006649038 |\n",
            "|    clip_fraction        | 0.0444      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.77       |\n",
            "|    explained_variance   | 0.0667      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.36e+05    |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.00614    |\n",
            "|    std                  | 0.845       |\n",
            "|    value_loss           | 4.59e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 265          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071028257 |\n",
            "|    clip_fraction        | 0.056        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.74        |\n",
            "|    explained_variance   | 0.0702       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.7e+05      |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00645     |\n",
            "|    std                  | 0.84         |\n",
            "|    value_loss           | 4.65e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 271          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054112906 |\n",
            "|    clip_fraction        | 0.0415       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.73        |\n",
            "|    explained_variance   | 0.0701       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.52e+05     |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.00461     |\n",
            "|    std                  | 0.84         |\n",
            "|    value_loss           | 4.57e+05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 331        |\n",
            "|    iterations           | 45         |\n",
            "|    time_elapsed         | 278        |\n",
            "|    total_timesteps      | 92160      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00410999 |\n",
            "|    clip_fraction        | 0.0187     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.71      |\n",
            "|    explained_variance   | 0.0718     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.08e+05   |\n",
            "|    n_updates            | 440        |\n",
            "|    policy_gradient_loss | -0.00429   |\n",
            "|    std                  | 0.83       |\n",
            "|    value_loss           | 4.59e+05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 283          |\n",
            "|    total_timesteps      | 94208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045897933 |\n",
            "|    clip_fraction        | 0.0224       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.68        |\n",
            "|    explained_variance   | 0.074        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.25e+05     |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    std                  | 0.824        |\n",
            "|    value_loss           | 4.64e+05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 331        |\n",
            "|    iterations           | 47         |\n",
            "|    time_elapsed         | 290        |\n",
            "|    total_timesteps      | 96256      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00484755 |\n",
            "|    clip_fraction        | 0.0321     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.66      |\n",
            "|    explained_variance   | 0.1        |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.15e+05   |\n",
            "|    n_updates            | 460        |\n",
            "|    policy_gradient_loss | -0.00424   |\n",
            "|    std                  | 0.818      |\n",
            "|    value_loss           | 4.58e+05   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 296          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056386837 |\n",
            "|    clip_fraction        | 0.0444       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.66        |\n",
            "|    explained_variance   | 0.138        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.32e+05     |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00556     |\n",
            "|    std                  | 0.82         |\n",
            "|    value_loss           | 4.62e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 331         |\n",
            "|    iterations           | 49          |\n",
            "|    time_elapsed         | 302         |\n",
            "|    total_timesteps      | 100352      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004876645 |\n",
            "|    clip_fraction        | 0.0296      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.65       |\n",
            "|    explained_variance   | 0.144       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.76e+05    |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | -0.00348    |\n",
            "|    std                  | 0.813       |\n",
            "|    value_loss           | 4.65e+05    |\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model"
      ],
      "metadata": {
        "id": "patymimzJ0pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_model(env, model, num_episodes=10):\n",
        "    rewards = []\n",
        "    food_gaps = []\n",
        "    forest_shares = []\n",
        "    co2_scores = []\n",
        "\n",
        "    for ep in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        episode_food_gap = []\n",
        "        episode_forest = []\n",
        "        episode_co2 = []\n",
        "\n",
        "        while not done:\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            total_reward += reward\n",
        "\n",
        "            episode_food_gap.append(info[\"food_gap\"])\n",
        "            episode_forest.append(info[\"forest_share\"])\n",
        "            episode_co2.append(info[\"co2_reduction\"])\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "        food_gaps.append(np.mean(episode_food_gap))\n",
        "        forest_shares.append(np.mean(episode_forest))\n",
        "        co2_scores.append(np.mean(episode_co2))\n",
        "\n",
        "    print(\"📊 Evaluation Summary:\")\n",
        "    print(f\"Avg Total Reward over {num_episodes} episodes: {np.mean(rewards):.2f}\")\n",
        "    print(f\"Avg Food Gap: {np.mean(food_gaps):.2f}\")\n",
        "    print(f\"Avg Forest Share: {np.mean(forest_shares):.2f}\")\n",
        "    print(f\"Avg CO2 Reduction: {np.mean(co2_scores):.2f}\")\n",
        "\n",
        "    # Optional: Plot rewards\n",
        "    plt.plot(rewards, marker='o')\n",
        "    plt.title(\"Total Reward per Evaluation Episode\")\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Reward\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return rewards\n",
        "\n",
        "# Run evaluation\n",
        "evaluation_rewards = evaluate_model(env, model, num_episodes=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "TlxNc2GsEFuI",
        "outputId": "d80dfb7d-5d88-427c-da1f-8d4b600c6d91"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluation Summary:\n",
            "Avg Total Reward over 10 episodes: 2432.77\n",
            "Avg Food Gap: 1346663.59\n",
            "Avg Forest Share: 0.33\n",
            "Avg CO2 Reduction: 60861467.17\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t6AJVldsP1yC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}